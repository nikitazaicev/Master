\chapter{Conclusion}


Results show that \gls{gnn}s are capable of solving \gls{mwm}, but the approaches presented in this work showed worse performance overall comapared to a simple standard greedy algorithm. The margin between the results was not big enough to indicate that the approach was completely sensless. Compared to the greedy algorithm model showed some level of "understanding" of the task at hand and in some special cases even manages to beat the greedy algortihm. It is worth mentioning that theese cases were manualy chosen because of the way they abuse the naiveness of the greedy algorithm, but it does still indicate that such cases do exist and therefore there is value in using \gls{gnn} instead of a greedy algorithm. 

\section{Future work}

The fact that \gls{gnn} in this work underperformed does not neccessary mean that the \gls{gnn}s are in general unfit for \gls{mwm} problem. There several potential improvements at hand. A deeper or wider model can be trained, meaning adding more layers as well as neurons to each layer to potentialy improve models ability to recognise complex patterns at the cost of longer training and prediction times. However for this particular architecture adding more layers showed little to no effect. Theres also a variety of different architectures that can be tested. A semi-supervised or an unsupervised approach is a good potential candidate where precomputing the optimal solution would not be needed. Instead the model can try to find the best solution by incentivising it to get as high weight sum as possible, resembeling a game in a way .

\section{Final words}