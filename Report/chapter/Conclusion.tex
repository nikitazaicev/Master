\chapter{Conclusion}

The model showed some level of "understanding" of the task at hand and in some special cases even manages to beat the greedy algorithm. The best results achieved by the approach presented in this work showed that \gls{gnn}s are capable of solving \gls{mwm} and can in some cases beat greedy algorithm, but on average the performance was neither good nor consistent enough. The model on average achieved 90\% of what the greedy algorithm did, except for a few cases where the greedy algorithm was further away from the optimal result. 90\% performance does, however, indicate that there is potential for better performance, given some improvements. One of the main problems seems to be the lack of variety within the datasets used for training. Since the input graph can be virtually of any shape and form, it might be hard to cover all the possible cases. The models trained to specifically handle MNIST graphs managed to outperform the greedy algorithm by 3\% with the line graph implementation and 1\% with the edge prediction, but the graphs were so small in size that the optimal blossom algorithm was in fact faster. The experiments on MNIST graphs showed that better use for such a model could be in cases where all the graphs belong to some subclass of graphs which narrows down the variety. 

\section{Future work}

The fact that our \gls{gnn} model developed in this work underperformed does not necessarily mean that the \gls{gnn}s are in general unfit for \gls{mwm} problem. There are several potential improvements that can be made. A variety of different architectures can be tested. A deeper or wider model can be trained, adding more layers as well as neurons to potentially improve models' ability to recognize complex patterns at the cost of longer training and prediction times. However, for this particular architecture, adding more layers showed little to no effect. 

Another problem might be rooted in the supervised approach. Training a model based on the optimal solution has its pitfalls. The optimal solution can be completely different if even one edge is picked or not picked. A semi-supervised or an unsupervised approaches are good potential candidates where precomputing the optimal solution would not be needed.